# Tokenizers_demo
### This notebook demonstrates how the tokenizers and Natural Language Processors NLPs work under the hood. I hope it is simple enough for everyone to understand. [JUPYTER Notebook](https://github.com/kephalian/Tokenizers_demo/blob/main/TOKENIZER_ini_depth_Behind_the_pipeline_(PyTorch).ipynb)


Uses: SENTIMENT ANALYSIS PIPELINE of Hugging FACE


This notebook is my simplification of the Tokenizers demo, on how Tokenizers work found in Hugging Face Hub NLP Course, [Found Here https://huggingface.co/learn/nlp-course/chapter2/2?fw=p](https://huggingface.co/learn/nlp-course/chapter2/2?fw=p)

# Probably the first thing they should teach save your work (but they don't)

##### OTHER ITEMS OF INTEREST IN THIS REPO- 

[Loading a Hugging Face Transformer model and tokenizer from DISC Offline](https://github.com/kephalian/Tokenizers_demo/blob/main/Load_model_from_disc.md)


[SAVING a Hugging Face Transformer model and tokenizer to DISC FOR offline use](https://github.com/kephalian/Tokenizers_demo/blob/main/saving_a_model_to_disc.md)



Pull requests are solicited!
Prof. Dr. Santhosh Kumar Rajamani
MAEER MIT Pune's MIMER Medical College
Find me @ [ORCID](https://orcid.org/0000-0001-6552-5578)
        @ [Google Scholar](https://scholar.google.com/citations?hl=en&user=lU7vGgQAAAAJ)
