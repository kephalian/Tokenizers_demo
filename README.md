# Tokenizers_demo
### This notebook demonstrates how the tokenizers and Natural Language Processors NLPs work under the hood. I hope it is simple enough for everyone to understand. [JUPYTER Notebook](https://github.com/kephalian/Tokenizers_demo/blob/main/TOKENIZER_ini_depth_Behind_the_pipeline_(PyTorch).ipynb)


Uses: SENTIMENT ANALYSIS PIPELINE of Hugging FACE


This notebook is my simplification of the Tokenizers demo, on how Tokenizers work found in Hugging Face Hub NLP Course, [Found Here https://huggingface.co/learn/nlp-course/chapter2/2?fw=p](https://huggingface.co/learn/nlp-course/chapter2/2?fw=p)


Pull requests are solicited!
Prof. Dr. Santhosh Kumar Rajamani
MAEER MIT Pune's MIMER Medical College
Find me @ [ORCID](https://orcid.org/0000-0001-6552-5578)
        @ [Google Scholar](https://scholar.google.com/citations?hl=en&user=lU7vGgQAAAAJ)

[Loading a Hugging Face Transformer model and tokenizer from DISC]()
